
Curso rápido de 4 encontros com objetivo de introduzir a área de Interpretabilidade Mecanicista (Mechanistic Interpretability) para Large Language Models. A proposta compreende introdução a materiais teóricos, bibliotecas para interpretabilidade em Python, discussão de _papers_ recentes na área (publicados por organizações como Anthropic e Google DeepMind) e exercícios práticos. 

A área de Mechanistic Interpretability teve 93 _papers_ aceitos no ICML 2024, e tem como objetivo entender a lógica por trás de decisões de modelos de ML. Esses conhecimentos podem ser aplicados para aprimorar a transparência e a confiança em modelos amplamente empregados em diversos contextos. 

A proposta desse projeto de _upskilling_ conta com a realização de um Hackathon subsequente na área.

{{< button href="schedule" target="_self" >}}
Acessar a programação
{{< /button >}}
{{< button href="materials" target="_self" >}}
Acessar os materiais
{{< /button >}}
