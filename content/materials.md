---
title: Materiais
showTableOfContents: true
---

## Handbook

<iframe src="https://drive.google.com/file/d/1ZHs82RHO7OE_JwQKNwg4jMmzHy-0PWJE/preview" width="100%" height="700px">
</iframe>

## Aulas

### Aula 1

**Papers**:
- A Mathematical Framework for Transformer Circuits: https://transformer-circuits.pub/2021/framework/index.html

**Coding**:
- ARENA Transformers: [\[1.1\] Transformer from Scratch \(exercises\).ipynb](https://colab.research.google.com/drive/1lDwKASSYGE4y_7DuGSqlo3DN41NHrXEw?usp=sharing)
- ARENA Introdução a MechInterp: https://colab.research.google.com/drive/1gZdHsBL8Ljq7nSWJtxxlsI4JWHmllxxP?usp=sharing

### Aula 2

**Papers**:
- Interpretability In The Wild: A Circuit For Indirect Object Identification In GPT-2 Small: https://arxiv.org/pdf/2211.00593
- In-context Learning and Induction Heads: https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html

**Coding**:
- ARENA IOI: [\[1.3\] Indirect Object Identification \(exercises\).ipynb](https://colab.research.google.com/drive/1ZzLGDngppg5Y7CAKubww45RZrcXpVsrL?usp=sharing)

### Aula 3

**Papers**:
- Toy Models of Superposition: https://transformer-circuits.pub/2022/toy_model/index.html

**Coding**:
- ARENA Superposition: [\[1.4\] Superposition & Sparse Autoencoders \(exercises\).ipynb](https://colab.research.google.com/drive/1DSqMihSkocF4WtLtazpIpZoUzrlu3Vdb?usp=sharing)


### Aula 4

**Papers**:
- Sparse Autoencoders Find Highly Interpretable Features In Language Models: [Sparse Autoencoders Find Highly Interpretable Features in Language Models](https://arxiv.org/abs/2309.08600)
- Towards Monosemanticity: Decomposing Language Models With Dictionary Learning: https://transformer-circuits.pub/2023/monosemantic-features/index.html
- Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet: https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html

**Coding**:
ARENA Sparse Autoencoders: [\[1.4\] Superposition & Sparse Autoencoders \(exercises\).ipynb](https://colab.research.google.com/drive/1DSqMihSkocF4WtLtazpIpZoUzrlu3Vdb?usp=sharing)

## Extra

- Lista de _papers_ relevantes da área, de acordo com Neel Nanda: [An Extremely Opinionated Annotated List of My Favourite Mechanistic Interpretability Papers v2](https://www.alignmentforum.org/posts/NfFST5Mio7BCAQHPA/an-extremely-opinionated-annotated-list-of-my-favourite-1)
- Passos concretos para começar em MechInterp: [Concrete Steps to Get Started in Transformer Mechanistic Interpretability](https://www.neelnanda.io/mechanistic-interpretability/getting-started)
- 200 Problemas concretos abertos em MechInterp (pode ser interessante para o Hackathon, mas a lista está desatualizada): [200 Concrete Open Problems in Mechanistic Interpretability: Introduction](https://www.alignmentforum.org/posts/LbrPTJ4fmABEdEnLf/200-concrete-open-problems-in-mechanistic-interpretability)

## Oportunidades

- **ARENA** (Material base deste curso)
  - Oportunidade de passar 4 semanas em Londres estudando conteúdos práticos relevantes para pesquisa em AI Safety
  - https://www.arena.education/

- **MATS**
  - Programa para iniciar pesquisa em AI Safety com orientação de mentores com ampla experiência na área. Diversos autores de _papers_ utilizados nesse curso são mentores do MATS.
  - [Mentors — ML Alignment & Theory Scholars](https://www.matsprogram.org/mentors)
